\section{Project description}

Within only a couple of years, the rapid development of software libraries for numerical computations through data flow graphs (e.g., TensorFlow~\cite{tensorflow2015-whitepaper}, Theano~\cite{theano-full}, and MXNet~\cite{DBLP:journals/corr/ChenLLLWWXXZZ15}) has led to a fundamental change of paradigm in machine learning software.
These libraries are designed around the concept that a numerical program can often equivalently be expressed as a graph, where nodes represent mathematical operations and edges represent the data communicated between them.
Most notably, these libraries allow one to automatically deploy computation over one or more CPUs or GPUs within a single API, which makes it easy to maximize performance without specialized software expertise.\\

While these frameworks have originally been developed for the purpose of deep learning research, they are usually general enough to be applicable in a wide variety of other domains.
For this reason, the objective of this DIANA project is to conduct a feasibility study to answer whether statistical models used in particle physics (typically built with RooFit~\cite{Verkerke:2003ir} and HistFactory~\cite{Cranmer:2012sba}) could equivalently be expressed as computational graphs, to assess their capabilities and limits, and to determine how those frameworks would scale in terms of data and model parallelism.
In addition, the study should also determine whether existing probabilistic programming frameworks based data flow graphs (e.g., Edward~\cite{tran2016edward} and tensorprob~\cite{tensorprob2016}) are applicable for particle physics statistical models.
Where appropriate, the study should finally identify shortcomings, on which further software efforts could be dedicated.

\section{Roadmap}
\begin{itemize}
	\item April --- May, 2017
	      \begin{itemize}
	      	\item Design of representative benchmarks models in RooFit.
	      	\item Study of data flow graphs frameworks (e.g. TensorFlow, Theano, MXNet) or of probabilistic programming frameworks (e.g. Edward, tensorprob).
	      	\item Implementation of the benchmark models in one of the studied frameworks.
	      	\item Benchmarks evaluating their data and model parallelism.
	      \end{itemize}
	\item June, 2017
	      \begin{itemize}
	      	\item Technical report and recommendations for particle physics use cases.
	      	\item Implementation of the study and benchmark models in a secondary framework (if time permits).
	      \end{itemize}
	\item July --- August, 2017
	      \begin{itemize}
	      	\item Upstream software contributions to address the identified limitations (if any).
	      	\item Development of/Contribution to a probabilistic framework (if time permits).
	      \end{itemize}
\end{itemize}

\section{Deliverables}

\begin{itemize}
	\item Establish benchmarks that are representative of particle physics use cases.
	\item Technical report investigating the potential and limits of data flow graphs frameworks for particle physics statistical models.
	\item Contributions to a probabilistic framework (if time permits).
	\item Tutorial on data flow graphs targeted for physicists.
\end{itemize}
